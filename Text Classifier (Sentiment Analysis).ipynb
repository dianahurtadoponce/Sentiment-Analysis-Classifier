{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ce729f",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "\n",
    "During recent years a great surge in the use of text classification has arised, with the now normalised use of technology for nearly every aspect of life, it does not come as strange that solutions for some of the most common problems that come with this new commodities have also been developed, such is the case of Text Classification. Remoting ourselves back to the beginning of the internet it is possible to imagine how complicated it was to tackle simple problems such as comment flagging, back then blogs and chat forums probably had a really hard time making sure the exchanges that took place on them were not harmful to its users, but right now that has changed, learning from its past mistakes now it is possible to use Text Classification algorithms to take care of this vital tasks. Text classification is an ever growing area that has introduced new found perks for developers and users alike, in examples like the previously mentioned comment flagging or email spam filtering, but also in things like identifying negative and positive reviews, giving new found insights to companies about their products and their clients, these categorization of text data has introduced many solutions not only for web technologies but for life in general.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "From the previous stated reason surges the interest in developing a text classifier capable of identifying negative, neutral and positive statements, in order to undertake this work first it was necessary to select an adequate source of training data, many options were available but ultimately it was decided to work with a dataset consistent of the user reviews for popular 2020 life simulation video game ‘Animal Crossing’, this decision directly correlates with the objectives of the project, since the main purpose was to provide some novelty to the already widely explored and developed topic of Text classification, then the idea became developing a basic text classifier but trained specifically with video game reviews data so that it would be able to classify reviews mainly related to these topics. The objectives for this project were: \n",
    "1. that it could outperform, at least minimally, already existing solutions.\n",
    "2. To classify text data correctly into the selected categories\n",
    "3. Although not making a novel discovery, to indagate into an already well explored area from a different point of view.\n",
    "4. Develop on top of already existing technologies and solutions to apport some new insights in the chosen area.\n",
    "5. Make use of tensorflow models to construct the text classifier model.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "As previously stated the dataset is a compilation of user reviews for the video game ‘Animal Crossing’, a work by Thomas Mock and posted on the site Kaggle by Jesse Mostipak, this dataset consists 2999 unique reviews posted by users of the game on the reviews site ‘Metacritic’, although no specific mention of a licence is made anywhere in the documentation, it can be inferred from the following line ‘Potential Analyses: Reviews: Sentiment analysis, text analysis, scores, date effect’ that it is safe to use it with educational purposes, the data set consists of a single table which compiles information about the grade assigned by the user, their username, the text for the reviews itself and the date said review was published, although for the purposes of this work only two of those columns will be utilised, the grade and review columns, the first column stores integer values ranging from 0 to 10 which denotes the numerical evaluation of the game, and the second column stores a textual description of the opinion the user has about the game, the other 2 columns which will not be made use of store an alpahumerical value representing the name of the user on the site and a date.\n",
    "\n",
    "## Evalutation Methodology\n",
    "\n",
    "In order to evaluate the success of the text classifier models it has been decided to compare its accuracy and precision against the accuracy and precision of an already existing model, for this particular case a Naive Bayes classifier implemented using the NLTK library, there were many options already existing form the literature which could have been selected to compare the classifier against but Naive Bayes was specially selected because it was an implementation already familiar from the content explored in the lectures, additionally it is one the most common implementations and therefore a good point of comparison; the specific model used for this work is a work by Preethi Thakur from the 23rd of October 2022 via the website medium. The reason why accuracy was specially selected is because it constitutes the quintessential metric for comparing the performance of models, it helps with knowing how often the model makes the right predictions while precision shows how often the model selects the correct target class, with this two metrics is already possible to construct and idea of the performance of the models. To calculate the accuracy and precision of the models the Sklearn library already provides two methods to calculate those metrics that will be made use of in this work.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6067da2",
   "metadata": {},
   "source": [
    "# II. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628ce254",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "**the first step is to import all the libraries necessary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a86db33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import os\n",
    "import pickle\n",
    "import keras\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import SpatialDropout1D, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62dd69e",
   "metadata": {},
   "source": [
    "# Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71dbd9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>mds27272</td>\n",
       "      <td>My gf started playing before me. No option to ...</td>\n",
       "      <td>2020-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>lolo2178</td>\n",
       "      <td>While the game itself is great, really relaxin...</td>\n",
       "      <td>2020-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Roachant</td>\n",
       "      <td>My wife and I were looking forward to playing ...</td>\n",
       "      <td>2020-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Houndf</td>\n",
       "      <td>We need equal values and opportunities for all...</td>\n",
       "      <td>2020-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ProfessorFox</td>\n",
       "      <td>BEWARE!  If you have multiple people in your h...</td>\n",
       "      <td>2020-03-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grade     user_name                                               text  \\\n",
       "0      4      mds27272  My gf started playing before me. No option to ...   \n",
       "1      5      lolo2178  While the game itself is great, really relaxin...   \n",
       "2      0      Roachant  My wife and I were looking forward to playing ...   \n",
       "3      0        Houndf  We need equal values and opportunities for all...   \n",
       "4      0  ProfessorFox  BEWARE!  If you have multiple people in your h...   \n",
       "\n",
       "         date  \n",
       "0  2020-03-20  \n",
       "1  2020-03-20  \n",
       "2  2020-03-20  \n",
       "3  2020-03-20  \n",
       "4  2020-03-20  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data set and print the first rows\n",
    "reviews = pd.read_csv('user_reviews.csv')\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4989b4",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "**In its current state the data set is not appropriate to be used for the model, therefore the following section describes the processes performed on it to achieve the desired format**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83fa37",
   "metadata": {},
   "source": [
    "### Null Values\n",
    "\n",
    "The fists step is to check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c61fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grade        0\n",
       "user_name    0\n",
       "text         0\n",
       "date         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a copy of the data set and check for null values\n",
    "c_reviews=reviews.copy()\n",
    "c_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed3b7a",
   "metadata": {},
   "source": [
    "Luckily this dataset does not contain null values, so it is possible to move on to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad546786",
   "metadata": {},
   "source": [
    "### Sentiment Column\n",
    "\n",
    "A key piece of information needed for the sentiment analysis is the sentiment associated with each review, this could be 'positive', 'negative' or 'neutral', it is necessary to add an aditional column to the data set that contains this information.\n",
    "\n",
    "The data set contains a grade section, which, as the name suggest, assigns a 'grade' in accordance to the review, with values rangin from 0 to 10. To assign the sentiment tag a score greater than 5 would be considerate positive, a score equal to 5 neutral and if the score is less than this number it would be assigned negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52083027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1158\n",
       "10     752\n",
       "1      255\n",
       "9      253\n",
       "2      131\n",
       "4      105\n",
       "3       98\n",
       "8       91\n",
       "5       78\n",
       "6       44\n",
       "7       34\n",
       "Name: grade, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count how many reviews correspond to each grade\n",
    "c_reviews['grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c91ff659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise a function able to assign the appropiate sentiment tag according to the grade given by the user\n",
    "def sentiment_function(row):\n",
    "    \n",
    "    if row['grade'] == 5:\n",
    "        value = 'neutral'\n",
    "    elif row['grade'] >= 0 and row['grade'] <= 4:\n",
    "        value = 'negative'\n",
    "    elif row['grade'] >= 6 and row['grade'] <= 10 :\n",
    "        value = 'positive'\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b379eb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>mds27272</td>\n",
       "      <td>My gf started playing before me. No option to ...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>lolo2178</td>\n",
       "      <td>While the game itself is great, really relaxin...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Roachant</td>\n",
       "      <td>My wife and I were looking forward to playing ...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Houndf</td>\n",
       "      <td>We need equal values and opportunities for all...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ProfessorFox</td>\n",
       "      <td>BEWARE!  If you have multiple people in your h...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grade     user_name                                               text  \\\n",
       "0      4      mds27272  My gf started playing before me. No option to ...   \n",
       "1      5      lolo2178  While the game itself is great, really relaxin...   \n",
       "2      0      Roachant  My wife and I were looking forward to playing ...   \n",
       "3      0        Houndf  We need equal values and opportunities for all...   \n",
       "4      0  ProfessorFox  BEWARE!  If you have multiple people in your h...   \n",
       "\n",
       "         date sentiment  \n",
       "0  2020-03-20  negative  \n",
       "1  2020-03-20   neutral  \n",
       "2  2020-03-20  negative  \n",
       "3  2020-03-20  negative  \n",
       "4  2020-03-20  negative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply the previous function to a new column 'sentiment' and print data set\n",
    "c_reviews['sentiment'] = c_reviews.apply(sentiment_function, axis=1)\n",
    "c_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "899294cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    1747\n",
       "positive    1174\n",
       "neutral       78\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then print the count for reviews according to sentiment\n",
    "c_reviews['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d496167",
   "metadata": {},
   "source": [
    "### Reviews text cleaning\n",
    "\n",
    "The next step ensures the data is standarized, it will essentially modify or remove linguistical elements that could cause confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c889981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise a function to lower case the data, remove unicode characters, numbers and extra spaces\n",
    "def cleaning_function(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b0035c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>mds27272</td>\n",
       "      <td>my gf started playing before me no option to c...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>lolo2178</td>\n",
       "      <td>while the game itself is great really relaxing...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Roachant</td>\n",
       "      <td>my wife and i were looking forward to playing ...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Houndf</td>\n",
       "      <td>we need equal values and opportunities for all...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ProfessorFox</td>\n",
       "      <td>beware if you have multiple people in your hou...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grade     user_name                                               text  \\\n",
       "0      4      mds27272  my gf started playing before me no option to c...   \n",
       "1      5      lolo2178  while the game itself is great really relaxing...   \n",
       "2      0      Roachant  my wife and i were looking forward to playing ...   \n",
       "3      0        Houndf  we need equal values and opportunities for all...   \n",
       "4      0  ProfessorFox  beware if you have multiple people in your hou...   \n",
       "\n",
       "         date sentiment  \n",
       "0  2020-03-20  negative  \n",
       "1  2020-03-20   neutral  \n",
       "2  2020-03-20  negative  \n",
       "3  2020-03-20  negative  \n",
       "4  2020-03-20  negative  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the function to the reviews on the data set\n",
    "c_reviews['text']=c_reviews['text'].apply(lambda x:cleaning_function(x))\n",
    "c_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a20d5",
   "metadata": {},
   "source": [
    "### Stop words\n",
    "\n",
    "In this step the aim is to remove 'stop words', words that do not convey relevant meaning.\n",
    "\n",
    "The nltk library for stopwords will be used, but modified not to include stopwords that denote negative sentiment, in order for that meaning not to be lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60800d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#download nltk library\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "babe235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified stopwords list\n",
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \n",
    "             \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \n",
    "             'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', \n",
    "             'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \n",
    "             'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "             'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \n",
    "             'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', \n",
    "             'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', \n",
    "             'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', \n",
    "             'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', \n",
    "             't', 'can', 'will', 'just', 'don', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', \n",
    "             'y', 'ma']\n",
    "\n",
    "#filter text in reviews\n",
    "def filter_stopwords(text):\n",
    "    words = text.split() \n",
    "    filtered = [word for word in words if word not in stop_words] \n",
    "    return ' '.join(filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dffe7819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>mds27272</td>\n",
       "      <td>gf started playing no option create island guy...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>lolo2178</td>\n",
       "      <td>game great really relaxing gorgeous cant ignor...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Roachant</td>\n",
       "      <td>wife looking forward playing game released bou...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Houndf</td>\n",
       "      <td>need equal values opportunities players island...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ProfessorFox</td>\n",
       "      <td>beware multiple people house want play game no...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grade     user_name                                               text  \\\n",
       "0      4      mds27272  gf started playing no option create island guy...   \n",
       "1      5      lolo2178  game great really relaxing gorgeous cant ignor...   \n",
       "2      0      Roachant  wife looking forward playing game released bou...   \n",
       "3      0        Houndf  need equal values opportunities players island...   \n",
       "4      0  ProfessorFox  beware multiple people house want play game no...   \n",
       "\n",
       "         date sentiment  \n",
       "0  2020-03-20  negative  \n",
       "1  2020-03-20   neutral  \n",
       "2  2020-03-20  negative  \n",
       "3  2020-03-20  negative  \n",
       "4  2020-03-20  negative  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_reviews['text']=c_reviews['text'].apply(lambda x:filter_stopwords(x))\n",
    "c_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12205c47",
   "metadata": {},
   "source": [
    "### Lematization\n",
    "\n",
    "\"Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meanings to one word.\"[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f405084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize function to do lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#filter text in reviews\n",
    "def lemmatize(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    sentence = ' '.join([lemmatizer.lemmatize(w) for w in words])\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95fd7924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>mds27272</td>\n",
       "      <td>gf started playing no option create island guy...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>lolo2178</td>\n",
       "      <td>game great really relaxing gorgeous cant ignor...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Roachant</td>\n",
       "      <td>wife looking forward playing game released bou...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Houndf</td>\n",
       "      <td>need equal value opportunity player island wif...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ProfessorFox</td>\n",
       "      <td>beware multiple people house want play game no...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grade     user_name                                               text  \\\n",
       "0      4      mds27272  gf started playing no option create island guy...   \n",
       "1      5      lolo2178  game great really relaxing gorgeous cant ignor...   \n",
       "2      0      Roachant  wife looking forward playing game released bou...   \n",
       "3      0        Houndf  need equal value opportunity player island wif...   \n",
       "4      0  ProfessorFox  beware multiple people house want play game no...   \n",
       "\n",
       "         date sentiment  \n",
       "0  2020-03-20  negative  \n",
       "1  2020-03-20   neutral  \n",
       "2  2020-03-20  negative  \n",
       "3  2020-03-20  negative  \n",
       "4  2020-03-20  negative  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_reviews['text']=c_reviews['text'].apply(lambda x: lemmatize(x))\n",
    "c_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d7eb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle data set and drop non-necessary columns\n",
    "r = c_reviews[['text', 'sentiment']]\n",
    "r = r.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be9b21",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "**To asses the performance of the model it will compare against a Naive Bayes classifier implemented using the NLTK library. The reasoning why Naive Bayes was selected is because it represents a perfect baseline since it is a linear classifier which makes it faster for large amounts of data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5fc13b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gf started playing no option create island guy...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>game great really relaxing gorgeous cant ignor...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wife looking forward playing game released bou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>need equal value opportunity player island wif...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beware multiple people house want play game no...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  gf started playing no option create island guy...  negative\n",
       "1  game great really relaxing gorgeous cant ignor...   neutral\n",
       "2  wife looking forward playing game released bou...  negative\n",
       "3  need equal value opportunity player island wif...  negative\n",
       "4  beware multiple people house want play game no...  negative"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first isolate required data from the cleaned data set\n",
    "nb = c_reviews[['text', 'sentiment']]\n",
    "nb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b43ce",
   "metadata": {},
   "source": [
    "*The following 4 cells of code are a citation from [3]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b74b56c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_7864\\498121657.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nb['sentiment'].replace({'positive':2, 'neutral':1, 'negative':0}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gf started playing no option create island guy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>game great really relaxing gorgeous cant ignor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wife looking forward playing game released bou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>need equal value opportunity player island wif...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beware multiple people house want play game no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  gf started playing no option create island guy...          0\n",
       "1  game great really relaxing gorgeous cant ignor...          1\n",
       "2  wife looking forward playing game released bou...          0\n",
       "3  need equal value opportunity player island wif...          0\n",
       "4  beware multiple people house want play game no...          0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert sentiment values to integer values\n",
    "nb['sentiment'].replace({'positive':2, 'neutral':1, 'negative':0}, inplace=True)\n",
    "nb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67f2f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "##using bag of words vectorization convert text from reviews\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=800)\n",
    "# vectorizing words and storing in variable X(predictor)\n",
    "X = cv.fit_transform(nb['text']).toarray()\n",
    "# predictor\n",
    "X\n",
    "# X size\n",
    "X.shape\n",
    "output: (1000, 800)\n",
    "# target\n",
    "y = nb.iloc[:,-1].values\n",
    "# y size\n",
    "y.shape\n",
    "output: (1000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f43d9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test sets\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "718fbf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian 0.5383333333333333\n",
      "Gaussian 0.7249794922963937\n",
      "Multinomial 0.84\n",
      "Multinomial 0.8321622416033276\n",
      "Bernoulli 0.735\n",
      "Bernoulli 0.8176220934470443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "# Naive Bayes Classifiers\n",
    "gnb = GaussianNB()\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()\n",
    "# fitting and predicting\n",
    "gnb.fit(X_tr, y_tr)\n",
    "y_pred_gnb = gnb.predict(X_te)\n",
    "mnb.fit(X_tr, y_tr)\n",
    "y_pred_mnb = mnb.predict(X_te)\n",
    "bnb.fit(X_tr, y_tr)\n",
    "y_pred_bnb = bnb.predict(X_te)\n",
    "# accuracy scores\n",
    "print(\"Gaussian\", accuracy_score(y_te, y_pred_gnb))\n",
    "print(\"Gaussian\", precision_score(y_te, y_pred_gnb, average='weighted'))\n",
    "print(\"Multinomial\", accuracy_score(y_te, y_pred_mnb))\n",
    "print(\"Multinomial\", precision_score(y_te, y_pred_mnb, average='weighted'))\n",
    "print(\"Bernoulli\", accuracy_score(y_te, y_pred_bnb))\n",
    "print(\"Bernoulli\", precision_score(y_te, y_pred_bnb, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d3de47",
   "metadata": {},
   "source": [
    "# Text Representation\n",
    "\n",
    "**In order to use this data for a Sentiment Analysis classifier it first needs to be available in a format the machine is able to understand, the following describes exactly that process.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f420531f",
   "metadata": {},
   "source": [
    "### Tokenizing\n",
    "\n",
    "Using Keras tokenizer to vectorize the text from the reviews by transforming it into a sequence of integers so it can be processed by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c07873",
   "metadata": {},
   "source": [
    "*1. initialize tokenizer*\n",
    "*2. update internal vocabulary based on reviews*\n",
    "*3. transform text into a sequence of integers*\n",
    "*4. transform sequences into 2D numpy array*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b25296cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=6000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(r['text'])\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(r['text'])\n",
    "sequences_padded = pad_sequences(sequences, maxlen=100, truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a821cc2",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "Modify sentiment lables to one-hot encoding, which is a way to convert categorical data into a format computers can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2ddc654",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pd.get_dummies(r['sentiment']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e544343",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "**The next section concerns the initialization of the model for sentiment analysis, it is a tensorflow sequential model consiting of 6 keras layers, it uses embedding, dense, dropout, one dimensional convolutional and pooling layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5868aaa",
   "metadata": {},
   "source": [
    "*divide text from reviews into trainnig and test data 80-20, 80% for trainning and 20% for testing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bdd656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(sequences_padded, sentiment, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f2e864",
   "metadata": {},
   "source": [
    "*initialise sequential model incrementally*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acbc55c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          600000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 98, 32)            9632      \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 32)                0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610787 (2.33 MB)\n",
      "Trainable params: 610787 (2.33 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(6000, 100, input_length=100))\n",
    "model.add(Conv1D(32, 3, activation='selu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(32, activation='selu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d212949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "75/75 [==============================] - 14s 74ms/step - loss: 0.8088 - accuracy: 0.6128 - val_loss: 0.6737 - val_accuracy: 0.7483\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 4s 48ms/step - loss: 0.5091 - accuracy: 0.8174 - val_loss: 0.4772 - val_accuracy: 0.8183\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 4s 47ms/step - loss: 0.2931 - accuracy: 0.9116 - val_loss: 0.4150 - val_accuracy: 0.8417\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 4s 48ms/step - loss: 0.1751 - accuracy: 0.9591 - val_loss: 0.4053 - val_accuracy: 0.8533\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 4s 51ms/step - loss: 0.1002 - accuracy: 0.9742 - val_loss: 0.4134 - val_accuracy: 0.8567\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 4s 52ms/step - loss: 0.0681 - accuracy: 0.9796 - val_loss: 0.4281 - val_accuracy: 0.8650\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 4s 48ms/step - loss: 0.0519 - accuracy: 0.9825 - val_loss: 0.4600 - val_accuracy: 0.8667\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 4s 47ms/step - loss: 0.0375 - accuracy: 0.9900 - val_loss: 0.4879 - val_accuracy: 0.8533\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 4s 51ms/step - loss: 0.0273 - accuracy: 0.9946 - val_loss: 0.5138 - val_accuracy: 0.8583\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 4s 55ms/step - loss: 0.0185 - accuracy: 0.9971 - val_loss: 0.5380 - val_accuracy: 0.8617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ebfdaaadc0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e009296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 10ms/step\n",
      "Accuracy: 0.8616666666666667\n",
      "Precision: 0.8485022982635343\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(x_test), axis=-1)\n",
    "print(\"Accuracy:\", accuracy_score(np.argmax(y_test, axis=-1), y_pred))\n",
    "print(\"Precision:\", precision_score(np.argmax(y_test, axis=-1), y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4418da7",
   "metadata": {},
   "source": [
    "### Making Predictions with Sentiment Analysis Classifier\n",
    "\n",
    "**After having trained and calculated accuracy for our model, we can use it to analyze actual text and infere the sentiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "725784de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#first save the model\n",
    "model.save('my_sentinalysis_model.h5')\n",
    "with open('tknzr.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5db2e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and tokenizer\n",
    "import keras\n",
    "\n",
    "model = keras.models.load_model('my_sentinalysis_model.h5')\n",
    "with open('tknzr.pickle', 'rb') as handle:\n",
    "    tknzr = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e952a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize function to do sentiment analysis\n",
    "def sentinalysis(text):\n",
    "    # Tokenize and pad the input text\n",
    "    sequence = tknzr.texts_to_sequences([text])\n",
    "    sequence = pad_sequences(sequence, maxlen=100)\n",
    "\n",
    "    # Make a prediction using the trained model\n",
    "    sentiment_prediction = model.predict(sequence)[0]\n",
    "    if np.argmax(sentiment_prediction) == 0:\n",
    "        return 'Negative'\n",
    "    elif np.argmax(sentiment_prediction) == 1:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5dcc8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 309ms/step\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "eg_text = \"I hate the game\"\n",
    "sentiment = sentinalysis(eg_text)\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71584158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "eg_text = \"I love the game\"\n",
    "sentiment = sentinalysis(eg_text)\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d33a371",
   "metadata": {},
   "source": [
    "# III. Conclusions\n",
    "\n",
    "## Evalutation\n",
    "\n",
    "After having successfully implemented the model, finally it is possible to compare its accuracy and precision against that of the Naive Bayes classifier, first it must be stated that in the baseline there are three different implementations of Naives Bayes, Gaussian, Multinomial and Bernoulli each with different accuracy and precision scores of: 0.5383 and 0.7249, 0.84 and 0.8321, 0.735 and 0.8176 respectively, while the model implemented had an accuracy of 0.8616 and precision of 0.8485, proving that it performs better than all implementations of Naive Bayes for both precision and accuracy, with Multinomial Bayes being the closest contender at a difference in accuracy of only about 2 hundredths and a precision difference of only about 1 hundredth.\n",
    "\n",
    "## Summary and Conclusions\n",
    "\n",
    "In light of the results obtained it is possible to determine that the model was successful in its ambitions of developing a text classifier capable of identifying the sentiment of reviews, beating just slightly the accuracy and precision of already existing models, also when using it to predict the sentiment of real text it was also capable of assigning them the correct sentiment. The state to which text classifiers are developed leaves the model in this work paling in comparison, however it can not be entirely crossed out that it could still represent an, although minimal, contribution to the area of text classifying, more specifically review classifying for video games and not only that specific area, but the work carried out could possibly also be transferred to other areas like monitoring the comment exchange in social sites, customer support for the aforementioned video games and also for product analysis. The work carried out is not out of the ordinary and can easily be replicated with minimal previous knowledge on python and the area of natural language processing, alternatively other programming languages could be replicate the work on this project but by doing so it would result in library incompatibility making it far more complicated than the work already developed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7224d7cf",
   "metadata": {},
   "source": [
    "[1] GeeksForGeeks Contributors. 2023. Python | Lemmatization with NLTK. GeeksForGeeks. https://www.geeksforgeeks.org/python-lemmatization-with-nltk/\n",
    "\n",
    "[2] DeepChecks. 2023. DeepChecks Glossary: One-hot Encoding. DeepChecks. https://deepchecks.com/glossary/one-hot-encoding/#:~:text=One%2Dhot%20encoding%20in%20machine,algorithms%20to%20improve%20prediction%20accuracy.\n",
    "\n",
    "[3] Preethi Thakur. 2022. Sentiment Analysis with Naive Bayes Classifier | NLTK | Python Code | Machine Learning. Medium. https://medium.com/@tpreethi/undesrtand-naive-bayes-algorithm-in-simple-explanation-with-python-code-part-2-a2b91cbbf637"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
